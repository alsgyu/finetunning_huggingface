{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b652e967-be2c-40c3-80c9-254a3564932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_656943/1637480294.py:8: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(extract_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축 해제 완료: ./extracted_files\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "file_path = \"download.tar\"  # 압축 파일 경로 (여기에 파일 이름을 변경)\n",
    "extract_path = \"./extracted_files\"  # 압축 해제 경로\n",
    "\n",
    "try:\n",
    "    with tarfile.open(file_path, \"r:*\") as tar:  # `r:*`는 모든 tar 형식 지원\n",
    "        tar.extractall(extract_path)\n",
    "    print(f\"압축 해제 완료: {extract_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"압축 해제 실패: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263c0c70-02a0-4314-9a18-1210ef9b3ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축 해제된 파일 목록: ['147.속성기반_감정분석_데이터']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 압축 해제된 디렉토리 경로\n",
    "extract_path = \"./extracted_files\"\n",
    "\n",
    "# 디렉토리 내 파일 목록 확인\n",
    "file_list = os.listdir(extract_path)\n",
    "print(\"압축 해제된 파일 목록:\", file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53d4d8d4-6081-4381-9121-b0a73f0a23c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일이 디렉토리 안에 없습니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSON 파일이 있는 디렉토리\n",
    "directory_path = \"extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Training/01.원천데이터\"  # 압축 해제된 디렉토리 경로\n",
    "\n",
    "# 디렉토리에서 JSON 파일 검색\n",
    "json_files = [file for file in os.listdir(directory_path) if file.endswith(\".json\")]\n",
    "\n",
    "if not json_files:\n",
    "    print(\"JSON 파일이 디렉토리 안에 없습니다!\")\n",
    "else:\n",
    "    # 첫 번째 JSON 파일을 선택\n",
    "    json_path = os.path.join(directory_path, json_files[0])\n",
    "    print(f\"선택된 JSON 파일: {json_path}\")\n",
    "\n",
    "    # JSON 파일 로드\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # JSON 데이터를 Pandas DataFrame으로 변환\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # 데이터 확인\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86d10658-0773-435f-9c3d-48d3e8887e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합된 파일이 생성되었습니다: merged_file.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 분할 압축 파일들이 있는 경로\n",
    "part_files_path = \"extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Training/02.라벨링데이터\"\n",
    "output_zip = \"merged_file.zip\"  # 병합된 압축 파일 이름\n",
    "\n",
    "# .part 파일 병합\n",
    "with open(output_zip, \"wb\") as merged:\n",
    "    for part_file in sorted(os.listdir(part_files_path)):\n",
    "        if part_file.endswith(\".part0\") or \".part\" in part_file:\n",
    "            with open(os.path.join(part_files_path, part_file), \"rb\") as part:\n",
    "                merged.write(part.read())\n",
    "\n",
    "print(f\"병합된 파일이 생성되었습니다: {output_zip}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e35c6da1-eed9-42cf-a5ef-a610f0a6c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축이 성공적으로 해제되었습니다. 데이터는 final_extracted_data에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# 병합된 파일 압축 해제\n",
    "extracted_path = \"final_extracted_data\"  # 압축 해제될 폴더 경로\n",
    "\n",
    "with zipfile.ZipFile(output_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extracted_path)\n",
    "\n",
    "print(f\"압축이 성공적으로 해제되었습니다. 데이터는 {extracted_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "448bddc2-2929-4472-b537-15559db0fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged parts into: merged_data.tar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def merge_parts(part_folder, output_file):\n",
    "    with open(output_file, 'wb') as merged_file:\n",
    "        parts = sorted([os.path.join(part_folder, f) for f in os.listdir(part_folder) if f.startswith(\"TS\") and f.endswith(\".part0\")])\n",
    "        for part in parts:\n",
    "            with open(part, 'rb') as f:\n",
    "                merged_file.write(f.read())\n",
    "\n",
    "part_folder = \"extracted_files\"  # Replace with your folder path\n",
    "output_file = \"merged_data.tar\"\n",
    "merge_parts(part_folder, output_file)\n",
    "print(\"Merged parts into:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c39a53d3-a5e4-4207-9c38-645bde2a5928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_SNS_01.패션.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_SNS_02.화장품.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_SNS_03.가전.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_SNS_04.IT기기.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_SNS_05.생활.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_01.패션_1-1.여성의류.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_01.패션_1-2.남성의류.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_01.패션_1-3.패션슈즈.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_01.패션_1-4.잡화.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_02.화장품_2-1.스킨케어.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_02.화장품_2-2.헤어바디케어.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_02.화장품_2-3.메이크업뷰티소품.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_02.화장품_2-4.남성화장품.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_03.가전_3-1.영상음향가전.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_03.가전_3-2.생활미용욕실가전.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_03.가전_3-3.주방가전.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_03.가전_3-4.계절가전.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_04.IT기기_4-1.컴퓨터주변기기.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_04.IT기기_4-2.휴대폰주변기기.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_04.IT기기_4-3.카메라게임기태블릿.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_04.IT기기_4-4.자동차기기.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_05.생활_5-1.세제세정탈취제.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_05.생활_5-2.주방용품.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_05.생활_5-3.위생용품.zip.part0\n",
      "병합 중: extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터/VL_쇼핑몰_05.생활_5-4.청소세탁용품.zip.part0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def merge_parts(part_folder, output_file):\n",
    "    parts = sorted([os.path.join(part_folder, f) for f in os.listdir(part_folder) if f.endswith(\".part0\")])\n",
    "    if not parts:\n",
    "        print(\"병합할 .part 파일이 없습니다.\")\n",
    "        return\n",
    "\n",
    "    with open(output_file, 'wb') as merged_file:\n",
    "        for part in parts:\n",
    "            print(f\"병합 중: {part}\")\n",
    "            with open(part, 'rb') as f:\n",
    "                merged_file.write(f.read())\n",
    "\n",
    "part_folder = \"extracted_files/147.속성기반_감정분석_데이터/01-1.정식개방데이터/Validation/02.라벨링데이터\"  # .part 파일이 있는 폴더 경로\n",
    "output_file = \"merged_data4.tar\"  # 병합 결과 파일 이름\n",
    "merge_parts(part_folder, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3dbf832-accd-4c1b-b223-0648a027787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축 해제 완료: dataset/Validation/02.라벨링데이터/merged_data4.tar -> extracted_files/merged_data8\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def extract_zip(file_path, extract_to):\n",
    "    try:\n",
    "        # zip 파일 열기\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f\"압축 해제 완료: {file_path} -> {extract_to}\")\n",
    "    except Exception as e:\n",
    "        print(f\"압축 해제 실패: {file_path}\\n{e}\")\n",
    "\n",
    "# 압축 해제 경로 설정\n",
    "file_path = \"dataset/Validation/02.라벨링데이터/merged_data4.tar\"\n",
    "extract_to = \"extracted_files/merged_data8\"\n",
    "\n",
    "# 압축 해제 실행\n",
    "extract_zip(file_path, extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cbee3a09-e4e0-4823-8846-6f17b9923fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원천 데이터 샘플:\n",
      "    INDEX 도메인     카테고리                  상품명  \\\n",
      "0  528926  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "1  528928  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "2  528929  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "3  528931  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "4  528939  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "\n",
      "                                                 상품평 데이터구분  \n",
      "0  공간을 많이 차지하지 않아 좋아요 높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나...   쇼핑몰  \n",
      "1  메쉬소재라 옷이 너무 미끄러 지네요. 다림질하다 옷잡는게 더 일이 되어버렸습니다. ...   쇼핑몰  \n",
      "2  튼튼해 보이고 좋아요  근데 이거 다리 어떻게 피는지 설명이 안돼있어서 불편했는데 ...   쇼핑몰  \n",
      "3  여러가지 기능이 있어서 좋기도 하구요 서서 하기도 좋고 앉아서 하기도 좋습니다 뭐 ...   쇼핑몰  \n",
      "4  요즘 스팀다리미 유행인데 가격거품이 많은 것 같네요 개별로 스팀다리미 구매하고 사용...   쇼핑몰  \n",
      "\n",
      "JSON 파일로 저장 완료: dataset/Validation/01.원천데이터/merged_data7/원천데이터.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 원천 데이터 파일 경로\n",
    "xlsx_path = \"dataset/Validation/01.원천데이터/merged_data7/VS_5-4.청소세탁용품.xlsx\"\n",
    "json_output_path = \"dataset/Validation/01.원천데이터/merged_data7/원천데이터.json\"  # 변환된 JSON 파일 저장 경로\n",
    "\n",
    "# xlsx 파일 읽기\n",
    "source_df = pd.read_excel(xlsx_path)\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"원천 데이터 샘플:\")\n",
    "print(source_df.head())\n",
    "\n",
    "# JSON으로 저장\n",
    "source_df.to_json(json_output_path, orient=\"records\", force_ascii=False, lines=True)  # orient=\"records\"는 JSON을 레코드별로 저장\n",
    "print(f\"\\nJSON 파일로 저장 완료: {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c4cba3d-4a4e-4f75-a559-4247d5e5e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 성공!\n",
      "    INDEX 도메인     카테고리                  상품명  \\\n",
      "0  528926  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "1  528928  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "2  528929  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "3  528931  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "4  528939  생활  청소/세탁용품  OO 카** 다리미판 프리미엄 블랙   \n",
      "\n",
      "                                                 상품평 데이터구분  \n",
      "0  공간을 많이 차지하지 않아 좋아요 높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나...   쇼핑몰  \n",
      "1  메쉬소재라 옷이 너무 미끄러 지네요. 다림질하다 옷잡는게 더 일이 되어버렸습니다. ...   쇼핑몰  \n",
      "2  튼튼해 보이고 좋아요  근데 이거 다리 어떻게 피는지 설명이 안돼있어서 불편했는데 ...   쇼핑몰  \n",
      "3  여러가지 기능이 있어서 좋기도 하구요 서서 하기도 좋고 앉아서 하기도 좋습니다 뭐 ...   쇼핑몰  \n",
      "4  요즘 스팀다리미 유행인데 가격거품이 많은 것 같네요 개별로 스팀다리미 구매하고 사용...   쇼핑몰  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_path = \"dataset/Validation/01.원천데이터/merged_data7/원천데이터.json\"\n",
    "\n",
    "# JSON Lines 데이터를 DataFrame으로 읽기\n",
    "try:\n",
    "    df = pd.read_json(json_path, lines=True, encoding=\"utf-8\")\n",
    "    print(\"데이터 로드 성공!\")\n",
    "    print(df.head())  # 데이터 확인\n",
    "except ValueError as e:\n",
    "    print(f\"데이터 로드 실패: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ce29c539-538b-49a9-acc3-4835f066a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    공간을 많이 차지하지 않아 좋아요 높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나...\n",
      "1    메쉬소재라 옷이 너무 미끄러 지네요. 다림질하다 옷잡는게 더 일이 되어버렸습니다. ...\n",
      "2    튼튼해 보이고 좋아요  근데 이거 다리 어떻게 피는지 설명이 안돼있어서 불편했는데 ...\n",
      "3    여러가지 기능이 있어서 좋기도 하구요 서서 하기도 좋고 앉아서 하기도 좋습니다 뭐 ...\n",
      "4    요즘 스팀다리미 유행인데 가격거품이 많은 것 같네요 개별로 스팀다리미 구매하고 사용...\n",
      "Name: 상품평, dtype: object\n",
      "                                                 상품평    감정\n",
      "0  공간을 많이 차지하지 않아 좋아요 높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나...  None\n",
      "1  메쉬소재라 옷이 너무 미끄러 지네요. 다림질하다 옷잡는게 더 일이 되어버렸습니다. ...  None\n",
      "2  튼튼해 보이고 좋아요  근데 이거 다리 어떻게 피는지 설명이 안돼있어서 불편했는데 ...  None\n",
      "3  여러가지 기능이 있어서 좋기도 하구요 서서 하기도 좋고 앉아서 하기도 좋습니다 뭐 ...  None\n",
      "4  요즘 스팀다리미 유행인데 가격거품이 많은 것 같네요 개별로 스팀다리미 구매하고 사용...  None\n"
     ]
    }
   ],
   "source": [
    "# '상품평' 열만 추출\n",
    "reviews = df['상품평']\n",
    "\n",
    "# 리뷰 데이터의 샘플 확인\n",
    "print(reviews.head())\n",
    "\n",
    "# 데이터셋 형식 준비\n",
    "prepared_data = df[['상품평']].copy()  # 감정 레이블 추가 준비\n",
    "prepared_data['감정'] = None  # 예시로 레이블 추가 (긍정/부정/중립)\n",
    "\n",
    "print(prepared_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f3d8f3c-660c-4131-b48a-77a2fb3bfedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "    Index                                            RawText Source Domain  \\\n",
      "0  505942  살균에 관심히 많아서 구매했습니다 성능이 어떤지 확인은 안되지만 그래도 소독이 잘되...    쇼핑몰     생활   \n",
      "1  505945  사용할때마다 3초간 꾸욱 눌러야 딱한번 5분간 살균작동하고 또 꺼져서 매번 사용때마...    쇼핑몰     생활   \n",
      "2  505955  ㅇㅇㅇ 덕분에 화장실 청소도 너무 편해졌어요 무엇보다 향이 너무 좋아서 화장실이 더...    쇼핑몰     생활   \n",
      "3  505956  배송 빠르구요 화장실 변기 청소할 때 편하네요 변기에 그냥 버릴수 있다는 점이 제일...    쇼핑몰     생활   \n",
      "4  505957  변기청소 담당입니다 늘 재구매템이고 젤 좋은건 청소하고 물내리면 되는게 넘 편하네요...    쇼핑몰     생활   \n",
      "\n",
      "  MainCategory              ProductName ReviewScore Syllable Word     RDate  \\\n",
      "0      청소/세탁용품         OO 앱** UV 변기 살균기           5       69   15  20201113   \n",
      "1      청소/세탁용품         OO 앱** UV 변기 살균기           3      106   23  20200626   \n",
      "2      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       57   15  20220829   \n",
      "3      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       51   14  20220829   \n",
      "4      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       64   15  20220827   \n",
      "\n",
      "  GeneralPolarity                                            Aspects  \n",
      "0               1  [{'Aspect': '효과/성능/기능', 'SentimentText': '성능이 ...  \n",
      "1              -1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '매...  \n",
      "2               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': 'ㅇ...  \n",
      "3               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '화...  \n",
      "4               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '청...  \n",
      "Validation Data:\n",
      "    Index                                            RawText Source Domain  \\\n",
      "0  528926  공간을 많이 차지하지 않아 좋아요 높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나...    쇼핑몰     생활   \n",
      "1  528928  메쉬소재라 옷이 너무 미끄러 지네요. 다림질하다 옷잡는게 더 일이 되어버렸습니다. ...    쇼핑몰     생활   \n",
      "2  528929  튼튼해 보이고 좋아요  근데 이거 다리 어떻게 피는지 설명이 안돼있어서 불편했는데 ...    쇼핑몰     생활   \n",
      "3  528931  여러가지 기능이 있어서 좋기도 하구요 서서 하기도 좋고 앉아서 하기도 좋습니다 뭐 ...    쇼핑몰     생활   \n",
      "4  528939  요즘 스팀다리미 유행인데 가격거품이 많은 것 같네요 개별로 스팀다리미 구매하고 사용...    쇼핑몰     생활   \n",
      "\n",
      "  MainCategory          ProductName ReviewScore Syllable Word     RDate  \\\n",
      "0      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙           4       52   13  20210331   \n",
      "1      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙           1       80   18  20201119   \n",
      "2      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙           5       61   14  20201113   \n",
      "3      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙           5       74   19  20201020   \n",
      "4      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙           5       78   17  20200917   \n",
      "\n",
      "  GeneralPolarity                                            Aspects  \n",
      "0               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '공...  \n",
      "1              -1  [{'Aspect': '재질/소재', 'SentimentText': '메쉬소재라 옷...  \n",
      "2               0  [{'Aspect': '내구성/견고성', 'SentimentText': '튼튼해 보...  \n",
      "3               1  [{'Aspect': '효과/성능/기능', 'SentimentText': '여러가지...  \n",
      "4               1  [{'Aspect': '내구성/견고성', 'SentimentText': '제품견고하...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "training_file = \"dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(1).json\"\n",
    "validation_file = \"dataset/Validation/02.라벨링데이터/merged_data8/5-4.청소세탁용품(45).json\"\n",
    "\n",
    "# JSON 파일 읽기\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# 로드\n",
    "train_df = load_json(training_file)\n",
    "val_df = load_json(validation_file)\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"Training Data:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(val_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "819b02a6-8ad6-4a7c-9f9f-238167daddf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(1).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(10).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(11).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(12).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(13).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(14).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(15).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(16).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(17).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(18).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(19).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(2).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(20).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(21).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(22).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(23).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(24).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(25).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(26).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(27).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(28).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(29).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(3).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(30).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(31).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(32).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(33).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(34).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(35).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(36).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(37).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(38).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(39).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(4).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(40).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(41).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(42).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(43).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(44).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(5).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(6).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(7).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(8).json\n",
      "처리 중: dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(9).json\n",
      "병합된 데이터 샘플:\n",
      "    Index                                            RawText Source Domain  \\\n",
      "0  505942  살균에 관심히 많아서 구매했습니다 성능이 어떤지 확인은 안되지만 그래도 소독이 잘되...    쇼핑몰     생활   \n",
      "1  505945  사용할때마다 3초간 꾸욱 눌러야 딱한번 5분간 살균작동하고 또 꺼져서 매번 사용때마...    쇼핑몰     생활   \n",
      "2  505955  ㅇㅇㅇ 덕분에 화장실 청소도 너무 편해졌어요 무엇보다 향이 너무 좋아서 화장실이 더...    쇼핑몰     생활   \n",
      "3  505956  배송 빠르구요 화장실 변기 청소할 때 편하네요 변기에 그냥 버릴수 있다는 점이 제일...    쇼핑몰     생활   \n",
      "4  505957  변기청소 담당입니다 늘 재구매템이고 젤 좋은건 청소하고 물내리면 되는게 넘 편하네요...    쇼핑몰     생활   \n",
      "\n",
      "  MainCategory              ProductName ReviewScore Syllable Word     RDate  \\\n",
      "0      청소/세탁용품         OO 앱** UV 변기 살균기           5       69   15  20201113   \n",
      "1      청소/세탁용품         OO 앱** UV 변기 살균기           3      106   23  20200626   \n",
      "2      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       57   15  20220829   \n",
      "3      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       51   14  20220829   \n",
      "4      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       64   15  20220827   \n",
      "\n",
      "  GeneralPolarity                                            Aspects  \n",
      "0               1  [{'Aspect': '효과/성능/기능', 'SentimentText': '성능이 ...  \n",
      "1              -1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '매...  \n",
      "2               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': 'ㅇ...  \n",
      "3               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '화...  \n",
      "4               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '청...  \n",
      "병합된 데이터를 저장했습니다: training_merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSON 파일이 위치한 디렉토리 경로\n",
    "json_folder = \"dataset/Training/라벨링데이터/merged_data2\"\n",
    "\n",
    "# 병합된 데이터를 저장할 리스트\n",
    "merged_data = []\n",
    "\n",
    "# 폴더 내 모든 JSON 파일을 순회하며 읽기\n",
    "for file_name in sorted(os.listdir(json_folder)):\n",
    "    if file_name.endswith(\".json\"):  # JSON 파일만 처리\n",
    "        file_path = os.path.join(json_folder, file_name)\n",
    "        print(f\"처리 중: {file_path}\")\n",
    "        try:\n",
    "            # JSON 파일 읽기\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = json.load(file)\n",
    "                if isinstance(data, list):\n",
    "                    merged_data.extend(data)  # 리스트 데이터를 병합\n",
    "                else:\n",
    "                    merged_data.append(data)  # 개별 JSON 객체를 병합\n",
    "        except Exception as e:\n",
    "            print(f\"파일 처리 중 오류 발생: {file_name}\\n{e}\")\n",
    "\n",
    "# 병합된 데이터를 Pandas DataFrame으로 변환\n",
    "merged_df = pd.DataFrame(merged_data)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"병합된 데이터 샘플:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# 병합된 데이터를 CSV 파일로 저장\n",
    "output_csv = \"training_merged_data.csv\"\n",
    "merged_df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "print(f\"병합된 데이터를 저장했습니다: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae4f6cf5-73fb-4d14-b45b-61d3045a78a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 샘플:\n",
      "    Index                                            RawText Source Domain  \\\n",
      "0  505942  살균에 관심히 많아서 구매했습니다 성능이 어떤지 확인은 안되지만 그래도 소독이 잘되...    쇼핑몰     생활   \n",
      "1  505945  사용할때마다 3초간 꾸욱 눌러야 딱한번 5분간 살균작동하고 또 꺼져서 매번 사용때마...    쇼핑몰     생활   \n",
      "2  505955  ㅇㅇㅇ 덕분에 화장실 청소도 너무 편해졌어요 무엇보다 향이 너무 좋아서 화장실이 더...    쇼핑몰     생활   \n",
      "3  505956  배송 빠르구요 화장실 변기 청소할 때 편하네요 변기에 그냥 버릴수 있다는 점이 제일...    쇼핑몰     생활   \n",
      "4  505957  변기청소 담당입니다 늘 재구매템이고 젤 좋은건 청소하고 물내리면 되는게 넘 편하네요...    쇼핑몰     생활   \n",
      "\n",
      "  MainCategory              ProductName ReviewScore Syllable Word     RDate  \\\n",
      "0      청소/세탁용품         OO 앱** UV 변기 살균기           5       69   15  20201113   \n",
      "1      청소/세탁용품         OO 앱** UV 변기 살균기           3      106   23  20200626   \n",
      "2      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       57   15  20220829   \n",
      "3      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       51   14  20220829   \n",
      "4      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개           5       64   15  20220827   \n",
      "\n",
      "  GeneralPolarity                                            Aspects  \n",
      "0               1  [{'Aspect': '효과/성능/기능', 'SentimentText': '성능이 ...  \n",
      "1              -1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '매...  \n",
      "2               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': 'ㅇ...  \n",
      "3               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '화...  \n",
      "4               1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '청...  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSON 파일 경로\n",
    "file_path = \"dataset/Training/라벨링데이터/merged_data2/5-4.청소세탁용품(1).json\"\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    try:\n",
    "        data = json.load(file)  # 전체 JSON 파일 로드\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError 발생: {e}\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame 샘플:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "282fca1a-7f9a-4cf4-91fb-58c558812f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터프레임의 열 목록:\n",
      "Index(['Index', 'RawText', 'Source', 'Domain', 'MainCategory', 'ProductName',\n",
      "       'ReviewScore', 'Syllable', 'Word', 'RDate', 'GeneralPolarity',\n",
      "       'Aspects'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터프레임의 열 목록:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c92724a0-623b-4aa7-b1cd-9a3deaf22fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment 데이터프레임 샘플:\n",
      "                        text label\n",
      "0           성능이 어떤지 확인은 안되지만     0\n",
      "1           소독이 잘되리라고 생각되네요      0\n",
      "2              자외선이 나오는거 같네요     1\n",
      "3  매번 사용때마다 다시 눌러야해서 불편합니다.     -1\n",
      "4                    UV등이 크고    -1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Aspects 열에서 SentimentText와 SentimentPolarity를 추출\n",
    "def extract_sentiments(aspects):\n",
    "    extracted = []\n",
    "    for aspect in aspects:\n",
    "        extracted.append({\n",
    "            \"text\": aspect.get(\"SentimentText\", \"\"),\n",
    "            \"label\": aspect.get(\"SentimentPolarity\", 0)\n",
    "        })\n",
    "    return extracted\n",
    "\n",
    "# Aspects 열에서 데이터를 추출하여 데이터프레임 생성\n",
    "sentiments = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    aspects = row['Aspects']  # Aspects 열 데이터\n",
    "    if isinstance(aspects, list):\n",
    "        sentiments.extend(extract_sentiments(aspects))\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentiments)\n",
    "\n",
    "print(\"Sentiment 데이터프레임 샘플:\")\n",
    "print(sentiment_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "41f3822d-0de1-408c-832a-15d388456488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Index', 'RawText', 'Source', 'Domain', 'MainCategory', 'ProductName', 'ReviewScore', 'Syllable', 'Word', 'RDate', 'GeneralPolarity', 'Aspects']\n",
      "['Index', 'RawText', 'Source', 'Domain', 'MainCategory', 'ProductName', 'ReviewScore', 'Syllable', 'Word', 'RDate', 'GeneralPolarity', 'Aspects']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.column_names)\n",
    "print(val_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b92c4c82-d281-4f3b-b004-04d1325aac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 열 이름 수정\n",
    "train_data = train_data.rename(columns={'RawText': 'text', 'GeneralPolarity': 'label'})\n",
    "valid_data = valid_data.rename(columns={'RawText': 'text', 'GeneralPolarity': 'label'})\n",
    "\n",
    "# Pandas DataFrame에서 Hugging Face Dataset으로 변환\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "valid_dataset = Dataset.from_pandas(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "519e058e-4dbc-4814-9aa6-d430901fb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e1057913-67ab-4b02-adf9-a72537c09d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/KcBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"beomi/KcBERT-base\",\n",
    "    num_labels=3  # 감정 분류: -1, 0, 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ae853-365f-4baf-9c32-7d2ee41068a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# 평가 지표 함수\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# Trainer 정의\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede2d8f-0218-42bc-9a35-67f7a7debeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "75e86621-571a-45b0-bec3-e777e35a3607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 데이터프레임 샘플:\n",
      "    Index                                            RawText Source Domain  \\\n",
      "0  505942  살균에 관심히 많아서 구매했습니다 성능이 어떤지 확인은 안되지만 그래도 소독이 잘되...    쇼핑몰     생활   \n",
      "1  505945  사용할때마다 3초간 꾸욱 눌러야 딱한번 5분간 살균작동하고 또 꺼져서 매번 사용때마...    쇼핑몰     생활   \n",
      "2  505955  ㅇㅇㅇ 덕분에 화장실 청소도 너무 편해졌어요 무엇보다 향이 너무 좋아서 화장실이 더...    쇼핑몰     생활   \n",
      "3  505956  배송 빠르구요 화장실 변기 청소할 때 편하네요 변기에 그냥 버릴수 있다는 점이 제일...    쇼핑몰     생활   \n",
      "4  505957  변기청소 담당입니다 늘 재구매템이고 젤 좋은건 청소하고 물내리면 되는게 넘 편하네요...    쇼핑몰     생활   \n",
      "\n",
      "  MainCategory              ProductName  ReviewScore  Syllable  Word  \\\n",
      "0      청소/세탁용품         OO 앱** UV 변기 살균기            5        69    15   \n",
      "1      청소/세탁용품         OO 앱** UV 변기 살균기            3       106    23   \n",
      "2      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개            5        57    15   \n",
      "3      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개            5        51    14   \n",
      "4      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개            5        64    15   \n",
      "\n",
      "      RDate  GeneralPolarity  \\\n",
      "0  20201113              1.0   \n",
      "1  20200626             -1.0   \n",
      "2  20220829              1.0   \n",
      "3  20220829              1.0   \n",
      "4  20220827              1.0   \n",
      "\n",
      "                                             Aspects  \n",
      "0  [{'Aspect': '효과/성능/기능', 'SentimentText': '성능이 ...  \n",
      "1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '매...  \n",
      "2  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': 'ㅇ...  \n",
      "3  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '화...  \n",
      "4  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '청...  \n",
      "\n",
      "Validation 데이터프레임 샘플:\n",
      "    Index                                            RawText Source Domain  \\\n",
      "0  528926  공간을 많이 차지하지 않아 좋아요 높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나...    쇼핑몰     생활   \n",
      "1  528928  메쉬소재라 옷이 너무 미끄러 지네요. 다림질하다 옷잡는게 더 일이 되어버렸습니다. ...    쇼핑몰     생활   \n",
      "2  528929  튼튼해 보이고 좋아요  근데 이거 다리 어떻게 피는지 설명이 안돼있어서 불편했는데 ...    쇼핑몰     생활   \n",
      "3  528931  여러가지 기능이 있어서 좋기도 하구요 서서 하기도 좋고 앉아서 하기도 좋습니다 뭐 ...    쇼핑몰     생활   \n",
      "4  528939  요즘 스팀다리미 유행인데 가격거품이 많은 것 같네요 개별로 스팀다리미 구매하고 사용...    쇼핑몰     생활   \n",
      "\n",
      "  MainCategory          ProductName  ReviewScore  Syllable  Word     RDate  \\\n",
      "0      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            4        52    13  20210331   \n",
      "1      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            1        80    18  20201119   \n",
      "2      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            5        61    14  20201113   \n",
      "3      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            5        74    19  20201020   \n",
      "4      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            5        78    17  20200917   \n",
      "\n",
      "   GeneralPolarity                                            Aspects  \n",
      "0              1.0  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '공...  \n",
      "1             -1.0  [{'Aspect': '재질/소재', 'SentimentText': '메쉬소재라 옷...  \n",
      "2              0.0  [{'Aspect': '내구성/견고성', 'SentimentText': '튼튼해 보...  \n",
      "3              1.0  [{'Aspect': '효과/성능/기능', 'SentimentText': '여러가지...  \n",
      "4              1.0  [{'Aspect': '내구성/견고성', 'SentimentText': '제품견고하...  \n",
      "\n",
      "Training 데이터프레임 열 목록: Index(['Index', 'RawText', 'Source', 'Domain', 'MainCategory', 'ProductName',\n",
      "       'ReviewScore', 'Syllable', 'Word', 'RDate', 'GeneralPolarity',\n",
      "       'Aspects'],\n",
      "      dtype='object')\n",
      "Validation 데이터프레임 열 목록: Index(['Index', 'RawText', 'Source', 'Domain', 'MainCategory', 'ProductName',\n",
      "       'ReviewScore', 'Syllable', 'Word', 'RDate', 'GeneralPolarity',\n",
      "       'Aspects'],\n",
      "      dtype='object')\n",
      "\n",
      "Training 데이터 크기: (4400, 12)\n",
      "Validation 데이터 크기: (500, 12)\n"
     ]
    }
   ],
   "source": [
    "# Training 데이터프레임 샘플 확인\n",
    "print(\"Training 데이터프레임 샘플:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Validation 데이터프레임 샘플 확인\n",
    "print(\"\\nValidation 데이터프레임 샘플:\")\n",
    "print(valid_data.head())\n",
    "\n",
    "# 열 확인\n",
    "print(\"\\nTraining 데이터프레임 열 목록:\", train_data.columns)\n",
    "print(\"Validation 데이터프레임 열 목록:\", valid_data.columns)\n",
    "\n",
    "# 데이터 크기 확인\n",
    "print(\"\\nTraining 데이터 크기:\", train_data.shape)\n",
    "print(\"Validation 데이터 크기:\", valid_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6fb5ad6d-45d3-46ab-b538-7e2e27640dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training 데이터 샘플:\n",
      "                        text label\n",
      "0           성능이 어떤지 확인은 안되지만     0\n",
      "1           소독이 잘되리라고 생각되네요      0\n",
      "2              자외선이 나오는거 같네요     1\n",
      "3  매번 사용때마다 다시 눌러야해서 불편합니다.     -1\n",
      "4                    UV등이 크고    -1\n",
      "\n",
      "Processed Validation 데이터 샘플:\n",
      "                                text label\n",
      "0                공간을 많이 차지하지 않아 좋아요      1\n",
      "1  높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나니 편합니다     1\n",
      "2               메쉬소재라 옷이 너무 미끄러 지네요.    -1\n",
      "3          다림질하다 옷잡는게 더 일이 되어버렸습니다.     -1\n",
      "4            상판이 너무 미끄러워 옷이 흘러내리네요.     -1\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentiment_data(df):\n",
    "    processed_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        aspects = eval(row['Aspects'])  # 문자열로 저장된 리스트를 실제 리스트로 변환\n",
    "        for aspect in aspects:\n",
    "            processed_data.append({\n",
    "                \"text\": aspect['SentimentText'],\n",
    "                \"label\": aspect['SentimentPolarity']\n",
    "            })\n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Training 데이터 전처리\n",
    "train_processed = preprocess_sentiment_data(train_data)\n",
    "\n",
    "# Validation 데이터 전처리\n",
    "valid_processed = preprocess_sentiment_data(valid_data)\n",
    "\n",
    "# 전처리된 데이터 확인\n",
    "print(\"Processed Training 데이터 샘플:\")\n",
    "print(train_processed.head())\n",
    "\n",
    "print(\"\\nProcessed Validation 데이터 샘플:\")\n",
    "print(valid_processed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d7062a08-d4e9-4522-81fa-f1e70f0bda3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Dataset 샘플:\n",
      "{'text': '성능이 어떤지 확인은 안되지만', 'label': '0'}\n",
      "\n",
      "Validation Dataset 샘플:\n",
      "{'text': '공간을 많이 차지하지 않아 좋아요 ', 'label': '1'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# 데이터셋 변환\n",
    "train_dataset = Dataset.from_pandas(train_processed)\n",
    "valid_dataset = Dataset.from_pandas(valid_processed)\n",
    "\n",
    "# 데이터셋 샘플 확인\n",
    "print(\"\\nTraining Dataset 샘플:\")\n",
    "print(train_dataset[0])\n",
    "\n",
    "print(\"\\nValidation Dataset 샘플:\")\n",
    "print(valid_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "004493dc-db98-4185-ac1d-9689ad7c4261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training 데이터 샘플:\n",
      "                        text  label\n",
      "0           성능이 어떤지 확인은 안되지만      0\n",
      "1           소독이 잘되리라고 생각되네요       0\n",
      "2              자외선이 나오는거 같네요      1\n",
      "3  매번 사용때마다 다시 눌러야해서 불편합니다.      -1\n",
      "4                    UV등이 크고     -1\n",
      "\n",
      "Processed Validation 데이터 샘플:\n",
      "                                text  label\n",
      "0                공간을 많이 차지하지 않아 좋아요       1\n",
      "1  높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나니 편합니다      1\n",
      "2               메쉬소재라 옷이 너무 미끄러 지네요.     -1\n",
      "3          다림질하다 옷잡는게 더 일이 되어버렸습니다.      -1\n",
      "4            상판이 너무 미끄러워 옷이 흘러내리네요.      -1\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentiment_data(df):\n",
    "    processed_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        aspects = eval(row['Aspects'])  # 문자열로 저장된 리스트를 실제 리스트로 변환\n",
    "        for aspect in aspects:\n",
    "            processed_data.append({\n",
    "                \"text\": aspect['SentimentText'],\n",
    "                \"label\": int(aspect['SentimentPolarity'])  # label 값을 숫자로 변환\n",
    "            })\n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Training 데이터 전처리\n",
    "train_processed = preprocess_sentiment_data(train_data)\n",
    "\n",
    "# Validation 데이터 전처리\n",
    "valid_processed = preprocess_sentiment_data(valid_data)\n",
    "\n",
    "# 전처리된 데이터 확인\n",
    "print(\"Processed Training 데이터 샘플:\")\n",
    "print(train_processed.head())\n",
    "\n",
    "print(\"\\nProcessed Validation 데이터 샘플:\")\n",
    "print(valid_processed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3d9183c2-a3db-4c66-83f7-b5a5b60084a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset columns: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Validation dataset columns: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 열 이름 확인\n",
    "print(\"Train dataset columns:\", train_dataset.column_names)\n",
    "print(\"Validation dataset columns:\", valid_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d2003030-e68c-4c76-817a-53a05f065670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 데이터 라벨 값 분포: label\n",
      "2    9018\n",
      "0    3518\n",
      "1     498\n",
      "Name: count, dtype: int64\n",
      "Validation 데이터 라벨 값 분포: label\n",
      "2    854\n",
      "0    654\n",
      "1     47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training 데이터 라벨 값 분포:\", train_processed['label'].value_counts())\n",
    "print(\"Validation 데이터 라벨 값 분포:\", valid_processed['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "276a34c0-f824-4538-88ec-5fe0d3721b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/KcBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"beomi/KcBERT-base\", num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "41647e4f-6324-4cfb-8b2f-6f27820ca4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_processed.sample(100, random_state=42))  # 100개 샘플링\n",
    "valid_dataset = Dataset.from_pandas(valid_processed.sample(50, random_state=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "12cfea8f-8c87-44e7-8f89-414bce09e137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels: {0, 1, 2}\n",
      "Validation labels: {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Training labels:\", set(train_dataset[\"label\"]))\n",
    "print(\"Validation labels:\", set(valid_dataset[\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dc992efd-cd4a-468d-8b0f-ac99c3704cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/KcBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# 레이블 개수 설정\n",
    "num_labels = len(set(train_dataset[\"label\"]))\n",
    "\n",
    "# 모델 초기화\n",
    "model = BertForSequenceClassification.from_pretrained(\"beomi/KcBERT-base\", num_labels=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "44938933-4fef-4c65-adf5-136d0cc61940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████| 13034/13034 [00:00<00:00, 30347.50 examples/s]\n",
      "Map: 100%|████████████████████| 1555/1555 [00:00<00:00, 30152.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def normalize_labels(example):\n",
    "    example[\"label\"] -= min_label  # 레이블 값이 0부터 시작하도록 변경\n",
    "    return example\n",
    "\n",
    "min_label = min(train_dataset[\"label\"])  # 가장 낮은 레이블 값 확인\n",
    "train_dataset = train_dataset.map(normalize_labels)\n",
    "valid_dataset = valid_dataset.map(normalize_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996b9d89-32bc-4f6e-9e76-05ad0bb70f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b00e6b-2972-4aa7-af29-159efbf2d7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name(0))  # 첫 번째 GPU 이름 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df573bd0-a08e-4031-97c5-7e6757bd7be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Columns: Index(['Index', 'RawText', 'Source', 'Domain', 'MainCategory', 'ProductName',\n",
      "       'ReviewScore', 'Syllable', 'Word', 'RDate', 'GeneralPolarity',\n",
      "       'Aspects'],\n",
      "      dtype='object')\n",
      "Validation Data Columns: Index(['Index', 'RawText', 'Source', 'Domain', 'MainCategory', 'ProductName',\n",
      "       'ReviewScore', 'Syllable', 'Word', 'RDate', 'GeneralPolarity',\n",
      "       'Aspects'],\n",
      "      dtype='object')\n",
      "Training Data Sample:\n",
      "     Index                                            RawText Source Domain  \\\n",
      "0  505942  살균에 관심히 많아서 구매했습니다 성능이 어떤지 확인은 안되지만 그래도 소독이 잘되...    쇼핑몰     생활   \n",
      "1  505945  사용할때마다 3초간 꾸욱 눌러야 딱한번 5분간 살균작동하고 또 꺼져서 매번 사용때마...    쇼핑몰     생활   \n",
      "2  505955  ㅇㅇㅇ 덕분에 화장실 청소도 너무 편해졌어요 무엇보다 향이 너무 좋아서 화장실이 더...    쇼핑몰     생활   \n",
      "3  505956  배송 빠르구요 화장실 변기 청소할 때 편하네요 변기에 그냥 버릴수 있다는 점이 제일...    쇼핑몰     생활   \n",
      "4  505957  변기청소 담당입니다 늘 재구매템이고 젤 좋은건 청소하고 물내리면 되는게 넘 편하네요...    쇼핑몰     생활   \n",
      "\n",
      "  MainCategory              ProductName  ReviewScore  Syllable  Word  \\\n",
      "0      청소/세탁용품         OO 앱** UV 변기 살균기            5        69    15   \n",
      "1      청소/세탁용품         OO 앱** UV 변기 살균기            3       106    23   \n",
      "2      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개            5        57    15   \n",
      "3      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개            5        51    14   \n",
      "4      청소/세탁용품  OO 다** 변기크리너 리필 12매입 8개            5        64    15   \n",
      "\n",
      "      RDate  GeneralPolarity  \\\n",
      "0  20201113              1.0   \n",
      "1  20200626             -1.0   \n",
      "2  20220829              1.0   \n",
      "3  20220829              1.0   \n",
      "4  20220827              1.0   \n",
      "\n",
      "                                             Aspects  \n",
      "0  [{'Aspect': '효과/성능/기능', 'SentimentText': '성능이 ...  \n",
      "1  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '매...  \n",
      "2  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': 'ㅇ...  \n",
      "3  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '화...  \n",
      "4  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '청...  \n",
      "Validation Data Sample:\n",
      "     Index                                            RawText Source Domain  \\\n",
      "0  528926  공간을 많이 차지하지 않아 좋아요 높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나...    쇼핑몰     생활   \n",
      "1  528928  메쉬소재라 옷이 너무 미끄러 지네요. 다림질하다 옷잡는게 더 일이 되어버렸습니다. ...    쇼핑몰     생활   \n",
      "2  528929  튼튼해 보이고 좋아요  근데 이거 다리 어떻게 피는지 설명이 안돼있어서 불편했는데 ...    쇼핑몰     생활   \n",
      "3  528931  여러가지 기능이 있어서 좋기도 하구요 서서 하기도 좋고 앉아서 하기도 좋습니다 뭐 ...    쇼핑몰     생활   \n",
      "4  528939  요즘 스팀다리미 유행인데 가격거품이 많은 것 같네요 개별로 스팀다리미 구매하고 사용...    쇼핑몰     생활   \n",
      "\n",
      "  MainCategory          ProductName  ReviewScore  Syllable  Word     RDate  \\\n",
      "0      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            4        52    13  20210331   \n",
      "1      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            1        80    18  20201119   \n",
      "2      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            5        61    14  20201113   \n",
      "3      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            5        74    19  20201020   \n",
      "4      청소/세탁용품  OO 카** 다리미판 프리미엄 블랙            5        78    17  20200917   \n",
      "\n",
      "   GeneralPolarity                                            Aspects  \n",
      "0              1.0  [{'Aspect': '편의성/사용성/활용도', 'SentimentText': '공...  \n",
      "1             -1.0  [{'Aspect': '재질/소재', 'SentimentText': '메쉬소재라 옷...  \n",
      "2              0.0  [{'Aspect': '내구성/견고성', 'SentimentText': '튼튼해 보...  \n",
      "3              1.0  [{'Aspect': '효과/성능/기능', 'SentimentText': '여러가지...  \n",
      "4              1.0  [{'Aspect': '내구성/견고성', 'SentimentText': '제품견고하...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "train_path = \"training_merged_data.csv\"\n",
    "valid_path = \"validation_merged_data.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "valid_df = pd.read_csv(valid_path)\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"Training Data Columns:\", train_df.columns)\n",
    "print(\"Validation Data Columns:\", valid_df.columns)\n",
    "print(\"Training Data Sample:\\n\", train_df.head())\n",
    "print(\"Validation Data Sample:\\n\", valid_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676eb969-434a-427c-bd14-34693b043d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data with Mapped Labels:\n",
      "                                              RawText  label\n",
      "0  살균에 관심히 많아서 구매했습니다 성능이 어떤지 확인은 안되지만 그래도 소독이 잘되...      2\n",
      "1  사용할때마다 3초간 꾸욱 눌러야 딱한번 5분간 살균작동하고 또 꺼져서 매번 사용때마...      0\n",
      "2  ㅇㅇㅇ 덕분에 화장실 청소도 너무 편해졌어요 무엇보다 향이 너무 좋아서 화장실이 더...      2\n",
      "3  배송 빠르구요 화장실 변기 청소할 때 편하네요 변기에 그냥 버릴수 있다는 점이 제일...      2\n",
      "4  변기청소 담당입니다 늘 재구매템이고 젤 좋은건 청소하고 물내리면 되는게 넘 편하네요...      2\n",
      "Validation Data with Mapped Labels:\n",
      "                                              RawText  label\n",
      "0  공간을 많이 차지하지 않아 좋아요 높낮이 조절방법을 몰라 처음에 좀 헤멨는데 알고나...      2\n",
      "1  메쉬소재라 옷이 너무 미끄러 지네요. 다림질하다 옷잡는게 더 일이 되어버렸습니다. ...      0\n",
      "2  튼튼해 보이고 좋아요  근데 이거 다리 어떻게 피는지 설명이 안돼있어서 불편했는데 ...      1\n",
      "3  여러가지 기능이 있어서 좋기도 하구요 서서 하기도 좋고 앉아서 하기도 좋습니다 뭐 ...      2\n",
      "4  요즘 스팀다리미 유행인데 가격거품이 많은 것 같네요 개별로 스팀다리미 구매하고 사용...      2\n"
     ]
    }
   ],
   "source": [
    "# 라벨 매핑\n",
    "label_mapping = {-1.0: 0, 0.0: 1, 1.0: 2}\n",
    "\n",
    "# 매핑 적용\n",
    "train_df[\"label\"] = train_df[\"GeneralPolarity\"].map(label_mapping).astype(int)\n",
    "valid_df[\"label\"] = valid_df[\"GeneralPolarity\"].map(label_mapping).astype(int)\n",
    "\n",
    "# GeneralPolarity 열 제거\n",
    "train_df = train_df[[\"RawText\", \"label\"]]\n",
    "valid_df = valid_df[[\"RawText\", \"label\"]]\n",
    "\n",
    "# 확인\n",
    "print(\"Training Data with Mapped Labels:\\n\", train_df.head())\n",
    "print(\"Validation Data with Mapped Labels:\\n\", valid_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e0ef65-a355-44d0-aa7c-5eff8d06b7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: Dataset({\n",
      "    features: ['RawText', 'label', '__index_level_0__'],\n",
      "    num_rows: 4378\n",
      "})\n",
      "Validation Dataset: Dataset({\n",
      "    features: ['RawText', 'label', '__index_level_0__'],\n",
      "    num_rows: 493\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Dataset으로 변환\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "valid_dataset = Dataset.from_pandas(valid_df)\n",
    "\n",
    "# 확인\n",
    "print(\"Training Dataset:\", train_dataset)\n",
    "print(\"Validation Dataset:\", valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1eac734-f89f-4162-a8b4-b14165a7f51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8837b130b1441e4a63dc12a0938b0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5d528eaf7149779c31ed5977573d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/493 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Training Dataset: Dataset({\n",
      "    features: ['label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 4378\n",
      "})\n",
      "Tokenized Validation Dataset: Dataset({\n",
      "    features: ['label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 493\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcBERT-base\")\n",
    "\n",
    "# 토크나이저 함수\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"RawText\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 토큰화 적용\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "train_dataset = train_dataset.remove_columns([\"RawText\"])\n",
    "valid_dataset = valid_dataset.remove_columns([\"RawText\"])\n",
    "\n",
    "# 확인\n",
    "print(\"Tokenized Training Dataset:\", train_dataset)\n",
    "print(\"Tokenized Validation Dataset:\", valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f837b-c6cf-494b-af41-f2b93430972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=False,\n",
    "    logging_dir=\"./logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4df31014-adbd-4f85-a24c-b592a6be6263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/ondevice/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='822' max='822' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [822/822 02:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.433028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.389500</td>\n",
       "      <td>0.484265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.389500</td>\n",
       "      <td>0.526763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/home/ondevice/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/shared/home/ondevice/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/shared/home/ondevice/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model/tokenizer_config.json',\n",
       " './fine_tuned_model/special_tokens_map.json',\n",
       " './fine_tuned_model/vocab.txt',\n",
       " './fine_tuned_model/added_tokens.json',\n",
       " './fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 실행\n",
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
